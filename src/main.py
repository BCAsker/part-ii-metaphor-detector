import pandas as pd
import torch
import torch.optim as optim
from prepared_input import Prepared
import deepmet_model
import time
import numpy as np

batch_size = 4
epochs = 3
n_folds = 10
learning_rate = 0.00001
metaphor_preference_parameter = 0.2


# Loss function as defined by equations (7)-(9) in the paper
# is_verb_task: True = VERB track, False = ALLPOS track
def loss_function(estimate_metaphors, estimate_literals, targets, is_verb_task):
    l0 = l1 = - torch.sum(targets * torch.log(estimate_metaphors) + (1 - targets) * torch.log(estimate_literals))
    return l0 * int(is_verb_task) + l1 * (1 - int(is_verb_task))


def train(train_dataset, model, model_num, fold_num, optimizer, epoch, start_time, is_verb_task):
    model.train()

    dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)

    for i_batch, sample_batched in enumerate(dataloader):
        optimizer.zero_grad()
        output = model(*sample_batched[1:7])
        loss = loss_function(output[:, 1], output[:, 0], sample_batched[0], is_verb_task)
        loss.backward()
        optimizer.step()

        if i_batch % 100 == 0:
            print("Model Number: " + str(model_num) +
                  ", Epoch: " + str(epoch) +
                  (" Verb" if is_verb_task else " All Pos") +
                  ", Training fold number: " + str(fold_num) +
                  ", Batch: " + str(i_batch) +
                  "/" + str(len(train_dataset) // batch_size + (1 if len(train_dataset) % batch_size > 0 else 0)) +
                  ", Time elapsed: " + str(time.time() - start_time))

        # TODO: Reduced training size for speed. Delete this later
        if i_batch == 10:
            break

    return model


def evaluate(eval_dataset, model):
    model.eval()
    dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size)

    start = time.time()

    probs = []
    with torch.no_grad():
        for i_batch, sample_batched in enumerate(dataloader):

            output = model(*sample_batched[1:7])
            probs.append(output)

            if i_batch % 500 == 0:
                print("Batch: " + str(i_batch) +
                      "/" + str(len(eval_dataset) // batch_size + (1 if len(eval_dataset) % batch_size > 0 else 0)) +
                      ", Time elapsed: " + str(time.time() - start))

    preds = [int(prob > metaphor_preference_parameter) for prob in torch.cat(probs, dim=0)[:, 1]]
    actuals = eval_dataset[:][0].tolist()

    tp = 0
    fp = 0
    fn = 0
    tn = 0

    for pred, actual in zip(preds, actuals):
        if pred == actual == 1:
            tp += 1
        elif pred == 1 and actual == 0:
            fp += 1
        elif pred == 0 and actual == 1:
            fn += 1
        else:
            tn += 1

    print("TP = " + str(tp) + ", FP = " + str(fp) + ", FN = " + str(fn) + ", TN = " + str(tn))

    acc = (tp + tn) / (tp + fp + fn + tn)
    prec = tp / (tp + fp) if tp + fp > 0 else 0
    rec = tp / (tp + fn) if tp + fn > 0 else 0
    f1 = (prec + rec) / 2

    print("Accuracy: " + str(acc))
    print("Precision: " + str(prec))
    print("Recall: " + str(rec))
    print("f1: " + str(f1))

    return f1


def multi_evaluate(eval_dataset, models):
    [model.eval() for model in models]
    dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size)

    start = time.time()

    probs = [[] for _ in range(len(models))]
    with torch.no_grad():
        for j_model, model in enumerate(models):
            for i_batch, sample_batched in enumerate(dataloader):

                if torch.cuda.is_available():
                    model = model.to(torch.device(0))

                output = model(*sample_batched[1:7])

                # Clear up GPU memory
                if torch.cuda.is_available():
                    model.cpu()

                probs[j_model].append(output)

                if i_batch % 500 == 0:
                    print("Model number: " + str(j_model) +
                          ", Batch: " + str(i_batch) +
                          "/" + str(len(eval_dataset) // batch_size + (1 if len(eval_dataset) % batch_size > 0 else 0)) +
                          ", Time elapsed: " + str(time.time() - start))

    # Concatenate the predictions for each batch, for each model
    probs = [torch.cat(one_model_probs) for one_model_probs in probs]

    # Add together the probabilities generated by the n_fold individual models
    probs = np.sum(probs, axis=0)

    preds = [int(prob / n_folds > metaphor_preference_parameter) for prob in probs[:, 1]]
    actuals = eval_dataset[:][0].tolist()

    tp = 0
    fp = 0
    fn = 0
    tn = 0

    for pred, actual in zip(preds, actuals):
        if pred == actual == 1:
            tp += 1
        elif pred == 1 and actual == 0:
            fp += 1
        elif pred == 0 and actual == 1:
            fn += 1
        else:
            tn += 1

    print("TP = " + str(tp) + ", FP = " + str(fp) + ", FN = " + str(fn) + ", TN = " + str(tn))

    acc = (tp + tn) / (tp + fp + fn + tn)
    prec = tp / (tp + fp) if tp + fp > 0 else 0
    rec = tp / (tp + fn) if tp + fn > 0 else 0
    f1 = (prec + rec) / 2

    print("Accuracy: " + str(acc))
    print("Precision: " + str(prec))
    print("Recall: " + str(rec))
    print("f1: " + str(f1))

    return f1


def main():
    pd.set_option("display.max_rows", 1000)
    pd.set_option("display.width", 0)

    # Load the dataframes containing the raw inputs for our embedding layer
    df_train_vua_verb = pd.read_csv("../data/VUA/train_vua_verb_tokenized.csv", index_col='token_id').dropna()
    df_train_vua_allpos = pd.read_csv("../data/VUA/train_vua_allpos_tokenized.csv", index_col='token_id').dropna()
    df_test_vua_verb = pd.read_csv("../data/VUA/test_vua_verb_tokenized.csv", index_col='token_id').dropna()
    df_test_vua_allpos = pd.read_csv("../data/VUA/test_vua_allpos_tokenized.csv", index_col='token_id').dropna()
    df_train_toefl_verb = pd.read_csv("../data/TOEFL/train_toefl_verb_tokenized.csv", index_col='token_id').dropna()
    df_train_toefl_allpos = pd.read_csv("../data/TOEFL/train_toefl_allpos_tokenized.csv", index_col='token_id').dropna()
    df_test_toefl_verb = pd.read_csv("../data/TOEFL/test_toefl_verb_tokenized.csv", index_col='token_id').dropna()
    df_test_toefl_allpos = pd.read_csv("../data/TOEFL/test_toefl_allpos_tokenized.csv", index_col='token_id').dropna()
    df_train_verb = pd.concat([df_train_vua_verb, df_train_toefl_verb])
    df_train_allpos = pd.concat([df_train_vua_allpos, df_train_toefl_allpos])

    train_verb_prepared = Prepared('train_verb', df_train_verb)
    train_allpos_prepared = Prepared('train_allpos', df_train_allpos)
    test_vua_verb_prepared = Prepared('test_vua_verb', df_test_vua_verb)
    test_vua_allpos_prepared = Prepared('test_vua_allpos', df_test_vua_allpos)
    test_toefl_verb_prepared = Prepared('test_toefl_verb', df_test_toefl_verb)
    test_toefl_allpos_prepared = Prepared('test_toefl_allpos', df_test_toefl_allpos)

    all_prepared = (train_verb_prepared, train_allpos_prepared, test_vua_verb_prepared, test_vua_allpos_prepared,
                    test_toefl_verb_prepared, test_toefl_allpos_prepared)

    # Make sure all inputs are of the same length
    max_length = max([prepared.length for prepared in all_prepared])
    for prepared in all_prepared:
        if prepared.length != max_length:
            prepared.prepare_inputs(max_length)

    if torch.cuda.is_available():
        for prepared in all_prepared:
            prepared.to_device(torch.device(0))

    train_verb_datasets = [torch.utils.data.TensorDataset(*tensors) for tensors in
                           train_verb_prepared.to_folds(n_folds)]
    train_allpos_datasets = [torch.utils.data.TensorDataset(*tensors) for tensors in
                             train_allpos_prepared.to_folds(n_folds)]

    test_vua_verb_dataset = torch.utils.data.TensorDataset(*test_vua_verb_prepared.get_tensors())
    test_vua_allpos_dataset = torch.utils.data.TensorDataset(*test_vua_allpos_prepared.get_tensors())
    test_toefl_verb_dataset = torch.utils.data.TensorDataset(*test_toefl_verb_prepared.get_tensors())
    test_toefl_allpos_dataset = torch.utils.data.TensorDataset(*test_toefl_allpos_prepared.get_tensors())

    print("Entering train")
    models = []
    start = time.time()
    # Train n_folds number of models
    for i in range(n_folds):
        model = deepmet_model.DeepMet(num_tokens=max_length, dropout_rate=0.2)
        if torch.cuda.is_available():
            model = model.to(torch.device(0))

        # Train this model on all but one of the folds
        for j in range(n_folds):
            optimizer = optim.Adam(model.parameters(), lr=learning_rate)
            if i != j:
                for epoch in range(1, epochs + 1):
                    model = train(train_verb_datasets[j], model, i, j, optimizer, epoch, start, True)
                    model = train(train_allpos_datasets[j], model, i, j, optimizer, epoch, start, False)

        models.append(model)
        torch.save(model.state_dict(), "../data/deepmet_model_2_" + str(i) + ".model")

        # Clear up GPU memory
        if torch.cuda.is_available():
            model.cpu()

    print("Done training!")

    best_verb_f1 = 0
    best_verb_f1_index = 0
    best_allpos_f1 = 0
    best_allpos_f1_index = 0

    # TODO: Load the weights and run from here

    print("Entering cross validation!")
    for i in range(n_folds):
        print("Model number: " + str(i))
        f1_verb = evaluate(train_verb_datasets[i], models[i])
        f1_allpos = evaluate(train_allpos_datasets[i], models[i])
        print()

        if f1_verb > best_verb_f1:
            best_verb_f1 = f1_verb
            best_verb_f1_index = i

        if f1_allpos > best_allpos_f1:
            best_allpos_f1 = f1_allpos
            best_allpos_f1_index = i

    print("best_verb_f1 = " + str(best_verb_f1) + ", ind = " + str(best_verb_f1_index))
    print("best_allpos_f1 = " + str(best_allpos_f1) + ", ind = " + str(best_allpos_f1_index))

    print("VUA Verb multi_evaluate")
    multi_evaluate(test_vua_verb_dataset, models)
    print()
    print("VUA All POS multi_evaluate")
    multi_evaluate(test_vua_allpos_dataset, models)
    print()
    print("TOEFL Verb multi_evaluate")
    multi_evaluate(test_toefl_verb_dataset, models)
    print()
    print("TOEFL All POS multi_evaluate")
    multi_evaluate(test_toefl_allpos_dataset, models)
    print()


if __name__ == '__main__':
    main()
